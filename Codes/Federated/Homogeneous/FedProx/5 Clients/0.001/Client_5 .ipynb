{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10d82a39",
   "metadata": {
    "id": "10d82a39"
   },
   "source": [
    "<b>IMPORT</b> </br>\n",
    "Importing the required libraries, including tensorflow, keras, pandas, numpy and flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9badf6b7",
   "metadata": {
    "id": "9badf6b7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, AUC, Precision, Recall\n",
    "from tensorflow.keras.applications import DenseNet121, VGG16, ResNet50\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.activations import sigmoid, softmax\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import backend\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import tensorflow_addons as tfa\n",
    "import flwr as fl\n",
    "from lime import lime_image\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961c92c2-18bf-47f2-9705-f440fb102082",
   "metadata": {
    "id": "961c92c2-18bf-47f2-9705-f440fb102082"
   },
   "source": [
    "<b>ENVIRONMENT SETTINGS</b></br>\n",
    "Disabling tensorflow warnings and allowing GPU growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f195af-b461-4c99-9099-9cbe5a463d3c",
   "metadata": {
    "id": "84f195af-b461-4c99-9099-9cbe5a463d3c"
   },
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\" #disabling tensorflow warnings\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\" #allowing GPU growth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45713208-58a1-4b68-8d86-cc2cd7b93cb3",
   "metadata": {
    "id": "45713208-58a1-4b68-8d86-cc2cd7b93cb3"
   },
   "source": [
    "<b>CLIENT SETTINGS</b></br>\n",
    "Defining the number of total clients and this clients ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e8cd2e-0016-4d08-9be5-f2bb3f630d2f",
   "metadata": {
    "id": "75e8cd2e-0016-4d08-9be5-f2bb3f630d2f"
   },
   "outputs": [],
   "source": [
    "clients = 5\n",
    "client_num = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b5c60b",
   "metadata": {
    "id": "95b5c60b"
   },
   "source": [
    "<b>STANDARD VALUES</b></br>\n",
    "Setting the standard values for model training such as image size, batch size, epochs, validation split, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83fa25a",
   "metadata": {
    "id": "b83fa25a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#images are entered into the neural network with a resolution of IMAGE_SIZE x IMAGE_SIZE\n",
    "IMAGE_SIZE = 320\n",
    "\n",
    "#three channels for the pixel representation of a color image\n",
    "CHANNELS = 3 \n",
    "\n",
    "#batch size, epochs and learning rate\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "#number of images from the dataset used for training & validation (maximum: 191027)\n",
    "IMAGES = 191027\n",
    "\n",
    "#80 % of the selected images are used for training, 20% for validation\n",
    "TRAIN_VALIDATION_SPLIT = 0.8\n",
    "\n",
    "#image agmentation is used with 50% of training images being augmented\n",
    "IMAGE_AUGMENTATION = True\n",
    "AUGMENTATION_SPLIT = 0.5\n",
    "\n",
    "#sigmoid activatino function is used in the final dense layer for classification\n",
    "ACTIVATION =  sigmoid\n",
    "\n",
    "#weights are initialised in the first epoch using a uniform distribution\n",
    "INITIALIZER = GlorotUniform(seed = 42)\n",
    "\n",
    "#the feature column \"Path\" includes the image paths to be classified.\n",
    "FEATURES = \"Path\"\n",
    "\n",
    "#the same five labels as in the original CheXpert paper are considered: Atelectasis, Cardiomegaly, Consolidation, Edema and Pleural Effusion\n",
    "LABELS = [\"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Pleural Effusion\"]\n",
    "\n",
    "#handling of the uncertainty labels: uncertain labels are mapped to one for the finding atelectasis and to zero for the other four diagnoses\n",
    "U_ONES_LABELS = [\"Atelectasis\"]\n",
    "U_ZEROS_LABELS = [\"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Pleural Effusion\"]\n",
    "\n",
    "#used metrics for performance evaluation and comparison: accuracy, AUROC, precision and recall (as F1-score)\n",
    "METRICS = [BinaryAccuracy(name = \"accuracy\"), AUC(name = \"auc\", multi_label = True), Precision(name = \"precision\"), Recall(name = \"recall\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef19565",
   "metadata": {
    "id": "1ef19565"
   },
   "source": [
    "<b>FUNCTIONS</b></br>\n",
    "Defining basic functions for preprocessing, reading in the images and plotting results, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e5d17",
   "metadata": {
    "id": "a08e5d17"
   },
   "outputs": [],
   "source": [
    "#reads in the file names of the images and converts them into same-size RGB-images with padding, thereby keeping the aspect ratio\n",
    "def parse_image(features, label):\n",
    "\n",
    "    image_string = tf.io.read_file(features)\n",
    "    image = tf.image.decode_jpeg(image_string, channels = CHANNELS)\n",
    "    image = tf.image.resize_with_pad(image, IMAGE_SIZE, IMAGE_SIZE) #padding keeps original aspect ratio of the image\n",
    "    image = tf.keras.applications.densenet.preprocess_input(image) #special preprocessing operation for the densenet structure\n",
    "\n",
    "    return image, label\n",
    "\n",
    "#creates a tensorflow dataset out of a pandas dataframe with the radiographs and selected labels\n",
    "def create_dataset(dataframe):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dataframe[FEATURES].values, dataframe[LABELS].values))\n",
    "    dataset = dataset.map(parse_image, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "#preprocessing of the created dataset and image augmentation for the training data\n",
    "def preprocess_dataset(dataset, is_training):\n",
    "    dataset = dataset.cache().shuffle(int(len(dataset)/100), reshuffle_each_iteration = False)\n",
    "\n",
    "    #augmentation for the training data, if IMAGE_AUGMENTATION is set to True\n",
    "    if is_training == True and IMAGE_AUGMENTATION == True:\n",
    "        print(\"Images in training dataset before augmentation: \" + str(len(dataset)))\n",
    "        dataset_augmented = dataset.take(int(AUGMENTATION_SPLIT*IMAGES*TRAIN_VALIDATION_SPLIT)).map(augment, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.concatenate(dataset_augmented)\n",
    "        print(\"Images in training dataset after augmentation: \" + str(len(dataset)))\n",
    "\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(buffer_size = tf.data.AUTOTUNE) #tensorflow input pipeline: batching the dataset and prefetching for increased efficiency\n",
    "\n",
    "    return dataset\n",
    "\n",
    "#image augmentation\n",
    "def augment(image, label):\n",
    "    image = tfa.image.rotate(image, random.uniform(-10, 10)*math.pi/180) #rotation of the image by up to 10 degrees in both directions\n",
    "    image = tf.image.central_crop(image, central_fraction = random.uniform(0.8, 1.0)) #randomly zooming into the image by up to 20 percent\n",
    "    image = tf.image.random_brightness(image, max_delta = 0.1) #manipulating the brightness by up to 10 percent\n",
    "    image = tf.image.random_contrast(image, lower = 0.9, upper = 1.1) #manipulating the contrast by up to 10 percent\n",
    "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE]) #resizing the image due to previous central crop function\n",
    "\n",
    "    return image, label\n",
    "\n",
    "#plotting the loss and metric curves over the epochs\n",
    "def plot_training(history):\n",
    "    history_dict = history.history\n",
    "    history_dict = list(history_dict)[:int(len(history_dict)/2)]\n",
    "\n",
    "    #creating a pyplot with two columns and a fixed size\n",
    "    num_rows = math.ceil(len(history_dict)/2)\n",
    "    num_cols = 2\n",
    "    pos = 1\n",
    "    plt.figure(figsize = (13, 5*num_rows))\n",
    "\n",
    "    #plotting training and validation curves for each metric and loss in one individual diagram\n",
    "    for h in history_dict:\n",
    "        plt.subplot(num_rows, num_cols, pos)\n",
    "        plt.plot(history.history[h])\n",
    "        plt.plot(history.history[\"val_\" + h])\n",
    "        plt.ylim([0.3, 0.9]) #fixing the range of the y-axis\n",
    "        plt.title(\"model \" + h, fontweight = \"bold\", fontsize = 13)\n",
    "        plt.ylabel(h)\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.legend([\"train\", \"valid\"], loc = \"best\")\n",
    "        pos += 1\n",
    "\n",
    "#plotting a roc curve of the model for a selected dataset (training, validation or test)\n",
    "def plot_roc_curve(data):\n",
    "    if data == \"training\":\n",
    "        dataset = train_ds\n",
    "        pred = pred_train\n",
    "        training_str = \"training\"\n",
    "        pos = 1\n",
    "    elif data == \"validation\":\n",
    "        dataset = valid_ds\n",
    "        pred = pred_valid\n",
    "        training_str = \"validation\"\n",
    "        pos = 2\n",
    "    elif data == \"test\":\n",
    "        dataset = test_ds\n",
    "        pred = pred_test\n",
    "        training_str = \"test\"\n",
    "        pos = 3\n",
    "\n",
    "    #getting the labels of the dataset\n",
    "    b = np.concatenate([b for a, b in dataset], axis = 0)\n",
    "\n",
    "    #initialising the value of the AUC sum\n",
    "    auc_sum = 0.0\n",
    "\n",
    "    #calculating the true- and false-positive rate of the model predictions for every diagnosis and thereby the AUROC metric\n",
    "    for l in range(len(LABELS)):\n",
    "        fpr, tpr, thresholds = roc_curve(b[:,l], pred[:,l])\n",
    "        auc_metric = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label = LABELS[l] + \" (AUC: \" + str(round(auc_metric, 4)) + \")\") #printing the indvidual metric values in the diagram\n",
    "        auc_sum += auc_metric\n",
    "\n",
    "    #creating a pyplot with a black bisector line for AUC = 0.5\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "    #defining title and axis descriptions\n",
    "    plt.title(\"model ROC curve (\" + training_str + \")\", fontweight = \"bold\", fontsize = 13)\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.legend(loc = \"best\")\n",
    "\n",
    "    #printing the average AUC value across all diagnoses\n",
    "    auc_average = auc_sum/len(LABELS)\n",
    "    print(\"Average AUC \" + \"(\" + training_str + \"): \" + str(auc_average))\n",
    "\n",
    "#plotting roc-curves for training, validation and test dataset\n",
    "def plot_roc_curves():\n",
    "\n",
    "    #creating a pyplot with two rows and columns\n",
    "    plt.figure(figsize = (13, 10))\n",
    "    num_rows = 2\n",
    "    num_cols = 2\n",
    "\n",
    "    plt.subplot(num_rows, num_cols, 1)\n",
    "    plot_roc_curve(\"training\") #plot training roc curve\n",
    "\n",
    "    plt.subplot(num_rows, num_cols, 2)\n",
    "    plot_roc_curve(\"validation\") #plot validation roc curve\n",
    "\n",
    "    plt.subplot(num_rows, num_cols, 3)\n",
    "    plot_roc_curve(\"test\") #plot test roc curve\n",
    "\n",
    "#plotting a number of examplary images with their respective labels and neuronal network's predictions\n",
    "def show_examples(data, number):\n",
    "    number = min(number, 10)\n",
    "\n",
    "    #selecting the right dataset\n",
    "    if data == \"training\":\n",
    "        dataset = train_ds\n",
    "        pred = pred_train\n",
    "    elif data == \"validation\":\n",
    "        dataset = valid_ds\n",
    "        pred = pred_valid\n",
    "    elif data == \"test\":\n",
    "        dataset = test_ds\n",
    "        pred = pred_test\n",
    "\n",
    "    num_rows = 1\n",
    "    num_cols = 1\n",
    "    pos = 1\n",
    "    label_pred_str = \"\"\n",
    "\n",
    "    for num in range(number): #loop for each radiograph\n",
    "\n",
    "        index = random.randint(0, len(dataset)) #randomly picking rdiograph\n",
    "        a, b = list(dataset.unbatch())[index] #getting the radiograph with its labels\n",
    "\n",
    "        print(\"\\033[1m\" + \"Image \" + str(num + 1) + \":\\t\" + \"\\033[0m\") #printing image umber\n",
    "\n",
    "        for l in range(len(LABELS)): #printing the radiograph with its respective labels and predictions\n",
    "\n",
    "            if(b[l] == 1.0):\n",
    "\n",
    "                label_pred_str += str(LABELS[l] + \": \")\n",
    "                label_pred_str += str(round(pred[index][l]*100, 2)) + \" \"\n",
    "\n",
    "            print(LABELS[l])\n",
    "            print(str(b.numpy()[l]) + \"\\t(Prediction: \" + str(round(pred[index][l]*100, 2)) + \"%)\")\n",
    "\n",
    "        fig = plt.figure(figsize = (13, 7)) #creating pyplot\n",
    "\n",
    "        plt.subplot(num_rows, num_cols, pos)\n",
    "        plt.imshow((a.numpy()*255).astype(\"uint8\")) #printing radiograph\n",
    "        plt.grid(None)\n",
    "        plt.title(\"Image \" + str(num + 1), fontweight = \"bold\", fontsize = 13)\n",
    "        plt.xlabel(label_pred_str) #image subscription\n",
    "\n",
    "        plt.show()\n",
    "        label_pred_str = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c3da3f",
   "metadata": {
    "id": "53c3da3f"
   },
   "source": [
    "<b>TRAIN & VALIDATION DATA FRAME</b></br>\n",
    "Reading in the CheXpert dataset. It can be downloaded at: https://stanfordmlgroup.github.io/competitions/chexpert/\n",
    "Subsequently filtering by frontal images and grouping by patient ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006111a8",
   "metadata": {
    "id": "006111a8",
    "outputId": "32e3f0e6-a67b-4b2b-e38d-fcad450e6bb9"
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"Chexpert/train.csv\") #reading in the dataframe via the csv-file\n",
    "\n",
    "#setting N/A labels to zero and uncertainty labels specific to u_ones and u_zeros in the CheXpert paper\n",
    "for l in LABELS:\n",
    "    if (l in U_ONES_LABELS):\n",
    "        dataframe[l][dataframe[l] < 0] = 1\n",
    "        dataframe[l] = dataframe[l].fillna(0)\n",
    "    elif (l in U_ZEROS_LABELS):\n",
    "        dataframe[l][dataframe[l] < 0] = 0\n",
    "        dataframe[l] = dataframe[l].fillna(0)\n",
    "\n",
    "#filtering out lateral radiographs\n",
    "dataframe = dataframe[dataframe[\"Frontal/Lateral\"] != \"Lateral\"][:min(191027, IMAGES)]\n",
    "\n",
    "#creating a patient and study column\n",
    "dataframe[\"Patient\"] = dataframe.Path.str.split('/', n=3, expand=True)[2].str.split(\"patient\", n=2, expand=True)[1]\n",
    "dataframe[\"Patient\"] = [i.lstrip(\"0\") for i in dataframe[\"Patient\"]]\n",
    "\n",
    "dataframe[\"Study\"] = dataframe.Path.str.split('/', n=4, expand=True)[3].str.split(\"study\", n=2, expand=True)[1]\n",
    "\n",
    "#grouping and shuffling the dataframe by patient\n",
    "patients = dataframe[\"Patient\"].unique()\n",
    "random.shuffle(patients)\n",
    "dataframe = dataframe.set_index(\"Patient\").loc[patients]\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5648893",
   "metadata": {
    "id": "e5648893",
    "outputId": "889d2996-f508-4119-9dfe-e482843403ed"
   },
   "outputs": [],
   "source": [
    "dataframe.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef64753d-7865-493e-bc11-61b251155438",
   "metadata": {
    "id": "ef64753d-7865-493e-bc11-61b251155438"
   },
   "source": [
    "<b>SELECTING CLIENT DATA</b></br>\n",
    "Sorting and selecting the data depending on the federated learning scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109f220-f4d6-43bb-ad3e-dbf99f22af41",
   "metadata": {
    "id": "1109f220-f4d6-43bb-ad3e-dbf99f22af41",
    "outputId": "7f52bf18-8825-4ff3-e517-8628d6ee92bb"
   },
   "outputs": [],
   "source": [
    "#Sorting the dataframe by age\n",
    "dataframe = dataframe.sort_values(by='Age')  \n",
    "\n",
    "# Calculating the indices for splitting the dataframe into five segments\n",
    "segment_size = len(dataframe) // clients\n",
    "start_index = (client_num - 1) * segment_size\n",
    "end_index = start_index + segment_size\n",
    "\n",
    "# include any remaining data points in last client\n",
    "if client_num == clients:\n",
    "    end_index = len(dataframe)\n",
    "\n",
    "# Selecting the client's segment of the dataframe\n",
    "dataframe = dataframe.iloc[start_index:end_index]\n",
    "\n",
    "dataframe.shape  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af07d8cb",
   "metadata": {
    "id": "af07d8cb"
   },
   "source": [
    "<b>TEST DATA FRAME</b></br>\n",
    "Reading in the test dataframe of the CheXpert dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31672603",
   "metadata": {
    "id": "31672603",
    "outputId": "a8832d77-3f09-4a5c-9408-15c180c666bc"
   },
   "outputs": [],
   "source": [
    "dataframe_test = pd.read_csv(\"Chexpert/valid.csv\") #reading in the test dataframe from the csv test file\n",
    "\n",
    "dataframe_test = dataframe_test[dataframe_test[\"Frontal/Lateral\"] != \"Lateral\"] #filtering out the lateral radiographs\n",
    "\n",
    "dataframe_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1c78c7",
   "metadata": {
    "id": "fe1c78c7",
    "outputId": "be30c7f0-b89a-46e6-cfe1-386d1685d378"
   },
   "outputs": [],
   "source": [
    "dataframe_test.shape #dimensions of the test dataframe:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd306d59",
   "metadata": {
    "id": "bd306d59"
   },
   "source": [
    "<b>CREATE TRAIN & VALIDATION DATASET</b></br>\n",
    "Creating a tf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c506a40e",
   "metadata": {
    "id": "c506a40e"
   },
   "outputs": [],
   "source": [
    "dataset = create_dataset(dataframe) #creating tf dataset out of the pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea35c5",
   "metadata": {
    "id": "baea35c5"
   },
   "source": [
    "<b>SPLIT TRAIN & VALIDATION DATASET</b></br>\n",
    "Splitting the dataset into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771bc283",
   "metadata": {
    "id": "771bc283",
    "outputId": "b4173c59-03a3-4747-c262-1fbf2e9cedd1"
   },
   "outputs": [],
   "source": [
    "train_ds = dataset.take(int(TRAIN_VALIDATION_SPLIT*len(dataset))) #taking the training part of the dataset\n",
    "valid_ds = dataset.skip(int(TRAIN_VALIDATION_SPLIT*len(dataset))) #taking the validation part of the dataset\n",
    "\n",
    "train_ds = preprocess_dataset(train_ds, True) #preprocessing with augmentation\n",
    "valid_ds = preprocess_dataset(valid_ds, False) #preprocessing without augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edd092b",
   "metadata": {
    "id": "5edd092b"
   },
   "source": [
    "<b>CREATE TEST DATASET</b></br>\n",
    "Creating the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873623fd",
   "metadata": {
    "id": "873623fd"
   },
   "outputs": [],
   "source": [
    "test_ds = create_dataset(dataframe_test) #creating the test dataset\n",
    "test_ds = preprocess_dataset(test_ds, False) #preprocessing without augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8735f7a8",
   "metadata": {
    "id": "8735f7a8"
   },
   "source": [
    "<b>MODEL</b></br>Creating CNN structure for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f85e4",
   "metadata": {
    "id": "9f2f85e4",
    "outputId": "916fdcec-29ef-4114-e21e-e595d34301c0",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creating the base model\n",
    "base_model = DenseNet121(\n",
    "    include_top = False, #no default final classification layer\n",
    "    weights = \"imagenet\", #Transfer learning with pretrained weights\n",
    "    input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS),\n",
    "    pooling = None, #no pooling\n",
    ")\n",
    "\n",
    "base_model.trainable = True #allow base model weight training\n",
    "\n",
    "inputs = tf.keras.Input(shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)) #model input shape\n",
    "\n",
    "#adding the different layers\n",
    "x = base_model(inputs, training = True) #base model\n",
    "x = tf.keras.layers.Conv2D(64, (3, 3))(x) #further convolutional layer\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x) #pooling layer\n",
    "x = tf.keras.layers.BatchNormalization()(x) #batchNorm layer\n",
    "x = tf.keras.layers.Dropout(0.4)(x) #dropout layer\n",
    "\n",
    "#final dense layer for classification\n",
    "outputs = tf.keras.layers.Dense(\n",
    "    len(LABELS), #number of nodes equals the number of classes\n",
    "    kernel_initializer = INITIALIZER, #initialising model weights with specific distribution\n",
    "    activation = ACTIVATION #setting activation function\n",
    ")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "#compiling the model\n",
    "model.compile(\n",
    "    loss = \"binary_crossentropy\", #model loss definition\n",
    "    optimizer = Adam(learning_rate = LEARNING_RATE), #setting optimizer to Adam with fixed learning rate\n",
    "    metrics = [BinaryAccuracy(name = \"accuracy\"), AUC(name = \"auc\", multi_label = True), Precision(name = \"precision\"), Recall(name = \"recall\")] #selecting predifined metrics\n",
    ")\n",
    "\n",
    "model.summary(expand_nested = False) #printing model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80448e3d",
   "metadata": {
    "id": "80448e3d"
   },
   "source": [
    "<b>TRAINING</b></br>\n",
    "Defining FL client and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98654585",
   "metadata": {
    "id": "98654585",
    "outputId": "aac18f0f-7268-45be-d712-7912075db682"
   },
   "outputs": [],
   "source": [
    "class Client(fl.client.NumPyClient):\n",
    "    def get_parameters(self, **kwargs):  # Accept and ignore any additional keyword arguments\n",
    "        return model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        model.set_weights(parameters)\n",
    "        history = model.fit(train_ds, epochs=EPOCHS, validation_data=valid_ds)\n",
    "        return model.get_weights(), len(train_ds), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        model.set_weights(parameters)\n",
    "        loss, accuracy, auc, precision, recall = model.evaluate(train_ds)\n",
    "        return loss, len(train_ds), {}\n",
    "\n",
    "\n",
    "fl.client.start_numpy_client(server_address=\"localhost:8080\", client=Client())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88ef175",
   "metadata": {
    "id": "b88ef175"
   },
   "source": [
    "<b>MODEL EVALUATION ON TEST DATASET</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa0b6ad",
   "metadata": {
    "id": "7fa0b6ad",
    "outputId": "21b462a9-6ac2-45f7-ef07-0538065fea55"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_ds) #evaluating model performance on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb68e45b",
   "metadata": {
    "id": "fb68e45b"
   },
   "source": [
    "<b>MODEL PREDICTIONS</b></br>\n",
    "Generating model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5f4ee",
   "metadata": {
    "id": "42d5f4ee"
   },
   "outputs": [],
   "source": [
    "pred_train = model.predict(train_ds)\n",
    "pred_valid = model.predict(valid_ds)\n",
    "pred_test = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b18ebfd2-955b-4894-8c3a-85e39aaf12d5",
   "metadata": {
    "id": "8f812772"
   },
   "source": [
    "<b>PLOT ROC CURVES</b></br>\n",
    "Plotting roc curves for training, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7885f4de",
   "metadata": {
    "id": "7885f4de",
    "outputId": "996425cd-deb0-404f-c5ce-a67a7817904e"
   },
   "outputs": [],
   "source": [
    "plot_roc_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>LIME EXPLANATIONS</b></br>\n",
    "Generating LIME explanations for a subset of test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to preprocess the image for LIME\n",
    "def preprocess_image_for_lime(path_to_image, img_size):\n",
    "    image_string = tf.io.read_file(path_to_image)\n",
    "    image = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n",
    "    image = tf.image.resize_with_pad(image, img_size, img_size)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    image = tf.keras.applications.densenet.preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "# Update the batch_predict function to process a batch of tensor images\n",
    "def batch_predict(images):\n",
    "    batch_images = tf.concat([preprocess_image_for_lime(path, IMAGE_SIZE) for path in images], axis=0)\n",
    "    preds = model.predict(batch_images)\n",
    "    return preds\n",
    "\n",
    "   \n",
    "# Creating the LIME explainer\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "# Defining the segmentation algorithm\n",
    "segmenter = SegmentationAlgorithm('quickshift', kernel_size=4, max_dist=200, ratio=0.2)\n",
    "\n",
    "# Paths to images used for the explanations\n",
    "specific_paths_to_images = [\n",
    "    'Chexpert/valid/patient64639/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64719/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64611/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64591/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64599/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64572/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64564/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64672/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64655/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64704/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64585/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64623/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64598/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64715/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64650/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64646/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64632/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64588/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64651/study1/view1_frontal.jpg',\n",
    "    'Chexpert/valid/patient64604/study1/view1_frontal.jpg'\n",
    "]\n",
    "\n",
    "# Store the explanation masks for consistency assessment\n",
    "explanation_masks = []\n",
    "\n",
    "# Iterate over selected images\n",
    "for path_to_image in specific_paths_to_images:\n",
    "    # Output the path of the image\n",
    "    print(f\"Processing Image: {path_to_image}\")\n",
    "\n",
    "    image_tensor = preprocess_image_for_lime(path_to_image, IMAGE_SIZE)\n",
    "    image_for_display = np.squeeze(image_tensor.numpy())\n",
    "\n",
    "    # Display the original image\n",
    "    plt.imshow(image_for_display / 2 + 0.5)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Generate explanation for the image\n",
    "    explanation = explainer.explain_instance(image_for_display.astype('double'), \n",
    "                                             model.predict,  \n",
    "                                             top_labels=5, \n",
    "                                             hide_color=0, \n",
    "                                             num_samples=100, \n",
    "                                             segmentation_fn=segmenter)\n",
    "    \n",
    "    top_label_index = explanation.top_labels[0]\n",
    "    top_label_name = LABELS[top_label_index]\n",
    "\n",
    "    _, mask = explanation.get_image_and_mask(top_label_index, positive_only=False, num_features=10, hide_rest=False)\n",
    "    \n",
    "    # Append the generated mask to the explanation_masks list\n",
    "    explanation_masks.append(mask)\n",
    "\n",
    "    # Display the explanation on the image\n",
    "    plt.imshow(mark_boundaries(image_for_display / 2 + 0.5, mask))\n",
    "    plt.title(f'Explanation for label: {top_label_name}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<b>Saving metrics</b></br>\n",
    "Saving metrics of explanations for later model comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the explanations\n",
    "explanation_dir = \"workspace/explanations_fl_5_5_FedAvg_001\"\n",
    "os.makedirs(explanation_dir, exist_ok=True)\n",
    "\n",
    "# Save the masks\n",
    "for i, mask in enumerate(explanation_masks):\n",
    "    # Save the mask to a compressed .npz file\n",
    "    mask_path = os.path.join(explanation_dir, f\"explanation_mask_fl_5_5_FedAvg_001_{i}.npz\")\n",
    "    np.savez_compressed(mask_path, mask=mask)\n",
    "\n",
    "# Save the manifest with details about the images and models\n",
    "manifest_path = os.path.join(explanation_dir, \"explanation_manifest_fl_5_5_FedAvg_001.csv\")\n",
    "with open(manifest_path, 'w') as file:\n",
    "    file.write(\"explanation_id,image_path,model_details\\n\")\n",
    "    for i, path_to_image in enumerate(specific_paths_to_images):\n",
    "        file.write(f\"{i},{path_to_image},central_model_001\\n\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Calculating Local Fidelity Scores</b></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store Local Fidelity Scores\n",
    "local_fidelity_scores = []\n",
    "\n",
    "# Iterate over selected images\n",
    "for path_to_image in specific_paths_to_images:\n",
    "    # Output the path of the image\n",
    "    print(f\"Processing Image: {path_to_image}\")\n",
    "\n",
    "    image_tensor = preprocess_image_for_lime(path_to_image, IMAGE_SIZE)\n",
    "    image_for_display = np.squeeze(image_tensor.numpy())\n",
    "\n",
    "    # Display the original image\n",
    "    plt.imshow(image_for_display / 2 + 0.5)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    explanation = explainer.explain_instance(image_for_display.astype('double'), \n",
    "                                             model.predict,  \n",
    "                                             top_labels=5, \n",
    "                                             hide_color=0, \n",
    "                                             num_samples=1000, \n",
    "                                             segmentation_fn=segmenter)\n",
    "    \n",
    "    top_label_index = explanation.top_labels[0]\n",
    "    top_label_name = LABELS[top_label_index]\n",
    "\n",
    "    # Get the explanation mask\n",
    "    _, mask = explanation.get_image_and_mask(top_label_index, positive_only=False, num_features=10, hide_rest=False)\n",
    "\n",
    "    # Ensure the explanation mask and image tensor have the same shape\n",
    "    mask = tf.image.resize(tf.expand_dims(mask, -1), (IMAGE_SIZE, IMAGE_SIZE))  \n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "    # Perform element-wise multiplication between the mask and image_tensor\n",
    "    masked_image = mask * image_tensor\n",
    "\n",
    "    # Apply the same preprocessing as used for model training data\n",
    "    masked_image = tf.keras.applications.densenet.preprocess_input(masked_image)\n",
    "\n",
    "    # Get the model's prediction for the masked image\n",
    "    prediction_with_explanation = model.predict(masked_image)\n",
    "\n",
    "    # Compare the model's prediction with the LIME's prediction\n",
    "    local_fidelity_score = np.mean(np.abs(model.predict(image_tensor) - prediction_with_explanation))\n",
    "    print(f\"Local Fidelity Score for {path_to_image}: {local_fidelity_score}\")\n",
    "\n",
    "    # Append the Local Fidelity Score to the list\n",
    "    local_fidelity_scores.append(local_fidelity_score)\n",
    "\n",
    "    # Convert the mask to an integer data type for processing boundaries\n",
    "    mask_as_int = (mask * 255).numpy().astype(np.uint8)\n",
    "\n",
    "    # Display the explanation on the image\n",
    "    plt.imshow(mark_boundaries(image_for_display / 2 + 0.5, mask_as_int[:, :, 0]))\n",
    "    plt.title(f'Explanation for label: {top_label_name}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Save the Local Fidelity Scores to a CSV file\n",
    "import csv\n",
    "folder_path = \"workspace/explanations_fl_5_5_FedAvg_001/\"\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "csv_file = os.path.join(folder_path, \"local_fidelity_scores_fl_5_5_FedAvg_001.csv\")\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Image_Path\", \"Local_Fidelity_Score\"]) \n",
    "    \n",
    "    # Iterate over selected images and write to CSV\n",
    "    for i, path_to_image in enumerate(specific_paths_to_images):\n",
    "        writer.writerow([path_to_image, local_fidelity_scores[i]])\n",
    "        print(f\"Writing to CSV: {path_to_image}, {local_fidelity_scores[i]}\")\n",
    "\n",
    "\n",
    "    # Iterate over selected images\n",
    "    for path_to_image in specific_paths_to_images:\n",
    "        # Calculate the local fidelity score\n",
    "        local_fidelity_score = np.mean(np.abs(model.predict(image_tensor) - prediction_with_explanation))\n",
    "\n",
    "        # Print the local fidelity score\n",
    "        print(f\"Local Fidelity Score for {path_to_image}: {local_fidelity_score}\")\n",
    "\n",
    "        # Append the local fidelity score to the list\n",
    "        local_fidelity_scores.append(local_fidelity_score)\n",
    "\n",
    "# Save the local fidelity scores to the CSV file\n",
    "with open(csv_file, mode='a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for i, path_to_image in enumerate(specific_paths_to_images):\n",
    "        writer.writerow([path_to_image, local_fidelity_scores[i]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509dbb3-2b25-4aa0-b528-9783d7ba5b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
